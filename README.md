# Бэкенд DatAFake и как его развернуть
## Просто о важном

Проект написан на Python 3.9

Для начала развертывания хорошо бы создать виртуальное окружение и установить туда всё, что перечислено в requirements.txt

На данный момент requirements.txt содержит только то, что нужно для его работы. Большая просьба не трогать этот файл.

Также надо добавить в файловую систему модели, используемые для работы API. Все модели грузятся в папку inference/photo_video/deepfake_model. На данный момент необходимы модели:

- resnet_focal_loss_v2.3_19.pth,
- resnet_detfake_v1.2_5.pt,
- resnet_focal_loss_v2.2_1.pth.

Они также перечислены в файле inference/src/config.py.

К сожалению, гитхаб не позволяет загружать такие тяжелые файлы в репозиторий. За файлами моделей можно обратиться к нашему Великому и ужасному чародею нейронных сетей Витале. Он даст ссылку на диск, где их можно скачать.

Поздравляю, Вы красавчик!

## Запуск API

Вы преодолели первый этап и хотите большего? Тогда предлагаю запустить наше API! Для этого откройте два терминала в той IDE, где вы работаете, и напишите следующие заклинания:

~~- в первом: uvicorn preprocessing.src.main:app --port 5000
- во втором: uvicorn inference.src.main:app --port 5050~~

С учетом логов сервис запускается по-другому:

- uvicorn preprocessing.src.main:app --port 5000 --log-config logging/preprocessing_logging.conf --workers 4
- uvicorn inference.src.main:app --port 5050 --log-config logging/inference_logging.conf --workers 4

Приписку --workers лучше оставить для многопоточности (будет запущено 4 процесса), однако можно и удалить при желании.

Убедительно прошу обратить внимание на первую строчку! Необходимо запускать приложение именно на этом порту. Если по какой-то причине он у Вас будет занят, напишите мне, я скажу как решить эту проблему.

Второе приложение можно запускать на любом порту, но не рекомендую делать это на 8000, просто чтобы не терять возможность использовать его для чего-то более важного.

Данные команды запускают приложения на localhost!

## Логирование

Логирование запускается автоматически при использовании команд, указанных выше.

Логи складываются в файлы logging/preprocessing.log и logging/inference.log для каждого из микросервисов. Ротация логов один день. Каждую полночь файл предыдущего дня переименовывается в формате preprocessing.log+дата, логи для нового дня продолжают складываться в preprocessing.log.

Файлы логов хранятся неделю, после чего удаляются. Для возможности отлова ошибок я убрала удаление загруженных на сервер файлов (на всякий случай, чтобы можно было повторить запрос в случае, если по логам не будет ясна ошибка).

## Тестирование эндпоинтов

Итак, Вы почти завершили путь в мир нашего прекрасного API! Осталось попробовать его в действии.

Самый простой способ для этого перейти по адресу localhost:5000/docs (в случае, если Вы не меняли первое заклинание из блока выше) или по адресу localhost:<номер порта>/docs (тут номер порта это тот порт, который Вы указали после ключа --port в блоке выше).

Тут вам откроется документация нашего API. Да, в ней всего один эндпоинт, не пугайтесь, все верно. Как говорил великий:

> Каждый дуб, когда-то был желудем!

Чтобы протестировать эндпоинт сделайте следующие шаги:

- нажмите на эндпоинт (слева есть стрелочка, чтобы его развернуть),
- нажмите на кнопку `Try it out`,
- рядом с надписью **upload_file** выберите файл, который хотите проанализировать,
- нажмите на синюю кнопку с надписью `Execute`.

Осталось подождать, пока файл обработается и Вы сможете посмотреть результат.

Поздравляю! Курс молодого бойца API пройден!

## Онли хардкор без смехуёчков

##### Эндпоинты, которые нужны фронту:

- /api/v1/files/analyze?model_num=<>&return_path=<>

Параметр model_num позволяет выбрать модель для обработки (при указании несуществующего номера модели перенаправляет запрос на модель по умолчанию). Необходимо указать значение int больше 0.

Параметр return_path позволяет указать возвращать ли имя загруженного файла после обработки. Нужно для работы бота и (возможно) фронта в будущем. Принимает значения bool, по умолчанию False.

На вход требует файл, отдает JSON с результатами в формате:
``` 
{ "message": string,
  "response":
      "<id>": list[float] или float,
  "dir_path": string  # альтернативно, если это указано в параметрах запроса
}
```

Где id - это порядковый номер лица в формате int начиная с 0, dir_path - имя присвоенное файлу на сервере.

Массив из float используется при анализе видео (вероятности для каждого кадра), а просто float при анализе фотографии.

##### Папка, куда кладутся фотографии лиц:

- preprocessing/media

На данный момент это так и написано у меня коряво, поэтому самостоятельно, Наташа, ты вряд ли это исправишь. Когда выделишь на диске конкретную папку, напиши мне, я оформлю по человечески путь до нее через переменные среды, чтобы ее можно было легко менять без копания в моём коде.

##### Порт для запуска основного контейнера

- 5000

На данный момент это так, потому что я не знала, какой порт мы выберем и какие ещё программы могут претендовать на тот же порт по умолчанию, потому взяла малоиспользуемый. Когда мы определимся с финальным портом окончательно, я перенастрою CORS для работы с ним и будем запускать уже на нём.
